{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to locally run parallel code with mpi4py in an IPython notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook introduces parallel exectution. Herefor, it is neccesary that you install pymofa locally by exectuing\n",
    "\n",
    "    &pip install -e .\n",
    "    \n",
    "in the pymofa root directory.\n",
    "\n",
    "The last update happed on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prerequisite for this is a working installation of some MPI distribution.\n",
    "\n",
    "Using Ubuntu or some derivative, I recommend using OpenMPI which can be istalled from the repository by means of the following packages:\n",
    "    \n",
    "    libopenmpi-dev, openmpi-bin, openmpi-doc\n",
    "\n",
    "Now, you can already run MPI enabled code from you shell by calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $mpirun -n [numbmer_of_threads] python [script_to_run.py]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To use MPI with iPython, one has to install ipyparallel:**\n",
    "\n",
    "via pip: \n",
    "\n",
    "    $pip install ipyparallel\n",
    "\n",
    "via conda:\n",
    "    \n",
    "    $conda install ipyparallel\n",
    "\n",
    "and then enable the Clusters tab in ipython via\n",
    "\n",
    "    $ipcluster nbextension enable\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make MPI acessable via mpi4py in an ipython notebook, one has to do the following:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open a shell and start the ipcontroller:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ipcontroller "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open another shell and start a number of engines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $mpirun -n [number of threads] ipengine --mpi=mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then connect to the engines via the following fragment of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "view = c[:]\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:3] /home/wbarfuss/Documents/Work/Software/pymofa/tutorial\n",
      "[stdout:4] /home/wbarfuss/Documents/Work/Software/pymofa/tutorial\n",
      "[stdout:5] /home/wbarfuss/Documents/Work/Software/pymofa/tutorial\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import os\n",
    "\n",
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return root\n",
    "path = find('02_LocalParallelization.ipynb', '/home/')\n",
    "print(path)\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make the code run on all of our engines (and not just on one), the following cells have to start with the [__parallel magic__](https://ipython.org/ipython-doc/3/parallel/magics.html) command *%%px*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:3] 2\n",
      "[stdout:4] 0\n",
      "[stdout:5] 1\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "com = MPI.COMM_WORLD\n",
    "print(com.Get_rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, that we have MPI running, and mpi4py recognizing the nodes and their ranks, we can continue with the predator prey exercise, that we know from the first tutorial.\n",
    "\n",
    "\n",
    "## The basic model\n",
    "First, define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predprey_model(prey_birth_rate=0.1, prey_mortality=0.1, \n",
    "                   predator_efficiency=0.1, predator_death_rate=0.01,\n",
    "                   initial_prey=1., initial_predators=1.,\n",
    "                   time_length=1000):\n",
    "    \"\"\"Discrete predetor prey model.\"\"\"\n",
    "    A = -1 * np.ones(time_length)\n",
    "    B = -1 * np.ones(time_length)\n",
    "    A[0] = initial_prey\n",
    "    B[0] = initial_predators\n",
    "    for t in range(1, time_length):\n",
    "        A[t] = A[t-1] + prey_birth_rate * A[t-1] - prey_mortality * B[t-1]*A[t-1]\n",
    "        B[t] = B[t-1] + predator_efficiency * B[t-1]*A[t-1] - predator_death_rate * B[t-1] +\\\n",
    "            0.02 * (0.5 - np.random.rand())\n",
    "    return A, B\n",
    "\n",
    "#preys, predators = predprey_model()\n",
    "#plt.plot(preys, label=\"preys\") \n",
    "#plt.plot(predators, label=\"predators\")\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "## pymofa\n",
    "Then import the experiment_handling class from pymofa and define a run function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# imports\n",
    "from pymofa.experiment_handling import experiment_handling as eh\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Path where to Store the simulated Data\n",
    "SAVE_PATH_RAW = \"./tutorial/dummy/pmX01data\"\n",
    "\n",
    "\n",
    "# Definingh the experiment execution function\n",
    "#      it gets paramater you want to investigate, plus `filename` as the last parameter\n",
    "def RUN_FUNC(prey_birth_rate,\n",
    "             coupling,\n",
    "             predator_death_rate,\n",
    "             initial_pop,\n",
    "             time_length,\n",
    "             store):  # <-- ich könnte hier die store function übergeben\n",
    "    \"\"\"Insightful docstring.\"\"\"\n",
    "    # poss. process\n",
    "    prey_mortality = coupling\n",
    "    predator_efficiency = coupling\n",
    "    initial_prey = initial_pop\n",
    "    initial_predators = initial_pop\n",
    "    # one could also do more complicated stuff here, e.g. \n",
    "    # drawing something from a random distribution\n",
    "    \n",
    "    # running the model\n",
    "    preys, predators = predprey_model(prey_birth_rate,\n",
    "                                      prey_mortality,\n",
    "                                      predator_efficiency,\n",
    "                                      predator_death_rate,\n",
    "                                      initial_prey,\n",
    "                                      initial_predators,\n",
    "                                      time_length)\n",
    "    \n",
    "    # preparing the data\n",
    "    res = pd.DataFrame({\"preys\": np.array(preys),\n",
    "                        \"predators\": np.array(predators)})\n",
    "    res.index.name = \"tstep\"\n",
    "    \n",
    "    # store run funcs model result\n",
    "    store(res)\n",
    "    \n",
    "    # determine exit status (if something went wrong)\n",
    "    # if exit status > 0 == run passed\n",
    "    # if exit status < 0 == Run Failed\n",
    "    exit_status = 42\n",
    "    \n",
    "    # RUN_FUNC needs to return exit_status \n",
    "    return exit_status\n",
    "\n",
    "\n",
    "# runfunc result format\n",
    "RUNFUNC_RESULTSFORM = pd.DataFrame(columns=[\"predators\", \"preys\"])\n",
    "RUNFUNC_RESULTSFORM.index.name = \"tstep\"\n",
    "\n",
    "\n",
    "# Parameter combinations to investiage\n",
    "prey_birth_rate = [0.09, 0.1, 0.11]\n",
    "coupling = [0.1]\n",
    "predator_death_rate = [0.005, 0.01, 0.05, 0.1]\n",
    "initial_pop = [1.0, 2.0]\n",
    "time_length = [1000]\n",
    "\n",
    "PARAM_COMBS = list(it.product(prey_birth_rate,\n",
    "                              coupling,\n",
    "                              predator_death_rate,\n",
    "                              initial_pop,\n",
    "                              time_length))\n",
    "\n",
    "\n",
    "# INDEX \n",
    "INDEX = {i: RUN_FUNC.__code__.co_varnames[i]\n",
    "         for i in range(RUN_FUNC.__code__.co_argcount-1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the necessary parameters, generate their combinations and feed them to an experiment handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:3] \n",
      "initializing pymofa experiment handle\n",
      "0 of 120 single computations left\n",
      "[stdout:4] \n",
      "initializing pymofa experiment handle\n",
      "detected 3 nodes in MPI environment\n",
      "0 of 120 single computations left\n",
      "[stdout:5] \n",
      "initializing pymofa experiment handle\n",
      "0 of 120 single computations left\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# Sample Size\n",
    "SAMPLE_SIZE = 5\n",
    "\n",
    "\n",
    "# initiate handle instance with experiment variables\n",
    "handle = eh(SAMPLE_SIZE,\n",
    "            PARAM_COMBS,\n",
    "            INDEX, RUN_FUNC,\n",
    "            RUNFUNC_RESULTSFORM,\n",
    "            SAVE_PATH_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally run the model - now in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:4] \n",
      "0 of 120 single computations left\n",
      "Splitting calculations to 2 nodes.\n",
      "Calculating 0 ...done.\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# Compute experiemnts raw data\n",
    "handle.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if everyting whent well, the calculations should have been splitted between all the engines that you've started in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run you experiments in scripts outside of an IPython notebook, simply run you experiment script (defining a run function, an experiment handle and calling the compute routine of that handle) with mpirun in a terminal "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
